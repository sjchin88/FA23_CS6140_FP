{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    " All required import statement"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# import tensorflow as tf\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from optuna.visualization.matplotlib import plot_param_importances\n",
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "\n",
    "sns.set_theme(style='white', palette='viridis')\n",
    "pal = sns.color_palette('viridis')\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "set_config(transform_output='pandas')\n",
    "pd.options.mode.chained_assignment = None\n",
    "seed = 42\n",
    "tss = TimeSeriesSplit(10)\n",
    "kf = KFold(n_splits=10)\n",
    "os.environ['PYTHONHASHSEED'] = '42'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\Users\\jinqw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " Prepare the function to read the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "dtypes = {\n",
    "    'stock_id': np.uint8,\n",
    "    'date_id': np.uint16,\n",
    "    'seconds_in_bucket': np.uint16,\n",
    "    'imbalance_buy_sell_flag': np.int8,\n",
    "    'time_id': np.uint16,\n",
    "}\n",
    "\n",
    "\n",
    "def read_data(data_path: str):\n",
    "    \"\"\"Read the data from the train and test csv files, split them into the x (features) and y(target)\n",
    "\n",
    "    Args:\n",
    "        data_path (str): absolute save path for the train and test data set \n",
    "\n",
    "    Returns:\n",
    "        X (dataframe): Independent features for training\n",
    "        y (dataframe): dependent features for training  \n",
    "        X_test (dataframe): Independent features for testing\n",
    "    \"\"\"\n",
    "    # Load data from the save path\n",
    "    train = pd.read_csv(f'{data_path}/train.csv',\n",
    "                        dtype=dtypes).drop(['row_id', 'time_id'], axis=1)\n",
    "    test = pd.read_csv(f'{data_path}/test.csv',\n",
    "                       dtype=dtypes).drop(['row_id', 'time_id'], axis=1)\n",
    "\n",
    "    # Check the data set\n",
    "    train.info()\n",
    "    print(train.head())\n",
    "    print(train.tail())\n",
    "    gc.collect()\n",
    "\n",
    "    # split data into X and y\n",
    "    X = train[~train.target.isna()]\n",
    "    y = X.pop('target')\n",
    "\n",
    "    # Test data dont have target column\n",
    "    X_test = test[~train.target.isna()]\n",
    "\n",
    "    X.info()\n",
    "    print(X.head())\n",
    "    return X, y, X_test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " This will prepare the imbalance feature"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def imbalance_calculator(x):\n",
    "\n",
    "    features = ['seconds_in_bucket', 'imbalance_buy_sell_flag',\n",
    "                'imbalance_size', 'matched_size', 'bid_size', 'ask_size',\n",
    "                'reference_price', 'far_price', 'near_price', 'ask_price', 'bid_price', 'wap',\n",
    "                'imb_s1', 'imb_s2'\n",
    "                ]\n",
    "\n",
    "    x_copy = x.copy()\n",
    "\n",
    "    x_copy['imb_s1'] = x.eval('(bid_size - ask_size) / (bid_size + ask_size)')\n",
    "    x_copy['imb_s2'] = x.eval(\n",
    "        '(imbalance_size - matched_size) / (matched_size + imbalance_size)')\n",
    "\n",
    "    prices = ['reference_price', 'far_price',\n",
    "              'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "\n",
    "    for i, a in enumerate(prices):\n",
    "        for j, b in enumerate(prices):\n",
    "            if i > j:\n",
    "                x_copy[f'{a}_{b}_imb'] = x.eval(f'({a} - {b}) / ({a} + {b})')\n",
    "                features.append(f'{a}_{b}_imb')\n",
    "\n",
    "    for i, a in enumerate(prices):\n",
    "        for j, b in enumerate(prices):\n",
    "            for k, c in enumerate(prices):\n",
    "                if i > j and j > k:\n",
    "                    max_ = x[[a, b, c]].max(axis=1)\n",
    "                    min_ = x[[a, b, c]].min(axis=1)\n",
    "                    mid_ = x[[a, b, c]].sum(axis=1)-min_-max_\n",
    "\n",
    "                    x_copy[f'{a}_{b}_{c}_imb2'] = (max_-mid_)/(mid_-min_)\n",
    "                    features.append(f'{a}_{b}_{c}_imb2')\n",
    "\n",
    "    return x_copy[features]\n",
    "\n",
    "\n",
    "ImbalanceCalculator = FunctionTransformer(imbalance_calculator)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " This section will prepare the cross_validation function\n",
    " cv = time series split of 10"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def cross_validation(estimator, save_path, X, y, X_test, cv=kf, label=''):\n",
    "    \"\"\"cross validation function\n",
    "\n",
    "    Args:\n",
    "        estimator (model): chosen model \n",
    "        save_path (str) : target directory to save the model\n",
    "        X (dataframe): Independent features for training\n",
    "        y (dataframe): dependent features for training  \n",
    "        X_test (dataframe): Independent features for testing\n",
    "        cv (split, optional): split for the cross validation. Defaults to tss.\n",
    "        label (str, optional): special label. Defaults to ''.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # Build the save path if not exist\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # initiate prediction arrays and score lists\n",
    "    val_predictions = np.zeros((len(X)))\n",
    "    # train_predictions = np.zeros((len(sample)))\n",
    "    train_scores, val_scores = [], []\n",
    "    best_model = None\n",
    "    best_model_train_score = 0\n",
    "    best_val_score = 0\n",
    "    best_fold = 0\n",
    "\n",
    "    # training model, predicting prognosis probability, and evaluating metrics\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "\n",
    "        model = clone(estimator)\n",
    "\n",
    "        # define train set\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "\n",
    "        # define validation set\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        # train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Save the model\n",
    "        joblib.dump(model, f'./{save_path}/{label}_{fold}.model')\n",
    "\n",
    "        # make predictions\n",
    "        train_preds = model.predict(X_train)\n",
    "        val_preds = model.predict(X_val)\n",
    "\n",
    "        val_predictions[val_idx] += val_preds\n",
    "\n",
    "        # evaluate model for a fold\n",
    "        train_score = mean_absolute_error(y_train, train_preds)\n",
    "        val_score = mean_absolute_error(y_val, val_preds)\n",
    "\n",
    "        # Update best model\n",
    "        if best_val_score == 0 or val_score < best_val_score:\n",
    "            best_val_score = val_score\n",
    "            best_model_train_score = train_score\n",
    "            best_model = model\n",
    "            best_fold = fold\n",
    "\n",
    "        # append model score for a fold to list\n",
    "        train_scores.append(train_score)\n",
    "        val_scores.append(val_score)\n",
    "\n",
    "    # This line print the average\n",
    "    print(f'Val Score: {np.mean(val_scores):.5f} ± {np.std(val_scores):.5f} | Train Score: {np.mean(train_scores):.5f} ± {np.std(train_scores):.5f} | {label}')\n",
    "    # Print best model score\n",
    "    for fold in range(len(val_scores)):\n",
    "        print(\n",
    "            f'fold:{fold}, Val Score: {val_scores[fold]}, Train Score: {train_scores[fold]}')\n",
    "    print(\n",
    "        f'Best validation score: {best_val_score}, associated train score: {best_model_train_score}, fold:{best_fold}')\n",
    "    joblib.dump(best_model, f'./{save_path}/best_model.model')\n",
    "\n",
    "    return val_scores, val_predictions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " Call the required function and run the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "models = [\n",
    "    ('LightGBM', LGBMRegressor(random_state=seed, objective='mse', device_type='gpu'))\n",
    "]\n",
    "X, y, X_test = read_data(\n",
    "    \"D:/OneDrive/NEU/CS6140/optiver-trading-at-the-close\")\n",
    "model_save_path = \"initial_run_feature_imb1\""
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5237980 entries, 0 to 5237979\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Dtype  \n",
      "---  ------                   -----  \n",
      " 0   stock_id                 uint8  \n",
      " 1   date_id                  uint16 \n",
      " 2   seconds_in_bucket        uint16 \n",
      " 3   imbalance_size           float64\n",
      " 4   imbalance_buy_sell_flag  int8   \n",
      " 5   reference_price          float64\n",
      " 6   matched_size             float64\n",
      " 7   far_price                float64\n",
      " 8   near_price               float64\n",
      " 9   bid_price                float64\n",
      " 10  bid_size                 float64\n",
      " 11  ask_price                float64\n",
      " 12  ask_size                 float64\n",
      " 13  wap                      float64\n",
      " 14  target                   float64\n",
      "dtypes: float64(11), int8(1), uint16(2), uint8(1)\n",
      "memory usage: 469.6 MB\n",
      "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
      "0         0        0                  0      3180602.69   \n",
      "1         1        0                  0       166603.91   \n",
      "2         2        0                  0       302879.87   \n",
      "3         3        0                  0     11917682.27   \n",
      "4         4        0                  0       447549.96   \n",
      "\n",
      "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
      "0                        1         0.999812   13380276.64        NaN   \n",
      "1                       -1         0.999896    1642214.25        NaN   \n",
      "2                       -1         0.999561    1819368.03        NaN   \n",
      "3                       -1         1.000171   18389745.62        NaN   \n",
      "4                       -1         0.999532   17860614.95        NaN   \n",
      "\n",
      "   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \n",
      "0         NaN   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704  \n",
      "1         NaN   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986  \n",
      "2         NaN   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950  \n",
      "3         NaN   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200  \n",
      "4         NaN   0.999394  16485.54   1.000016     434.10  1.0 -7.349849  \n",
      "         stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
      "5237975       195      480                540      2440722.89   \n",
      "5237976       196      480                540       349510.47   \n",
      "5237977       197      480                540            0.00   \n",
      "5237978       198      480                540      1000898.84   \n",
      "5237979       199      480                540      1884285.71   \n",
      "\n",
      "         imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
      "5237975                       -1         1.000317   28280361.74   0.999734   \n",
      "5237976                       -1         1.000643    9187699.11   1.000129   \n",
      "5237977                        0         0.995789   12725436.10   0.995789   \n",
      "5237978                        1         0.999210   94773271.05   0.999210   \n",
      "5237979                       -1         1.002129   24073677.32   1.000859   \n",
      "\n",
      "         near_price  bid_price   bid_size  ask_price   ask_size       wap  \\\n",
      "5237975    0.999734   1.000317   32257.04   1.000434  319862.40  1.000328   \n",
      "5237976    1.000386   1.000643  205108.40   1.000900   93393.07  1.000819   \n",
      "5237977    0.995789   0.995789   16790.66   0.995883  180038.32  0.995797   \n",
      "5237978    0.999210   0.998970  125631.72   0.999210  669893.00  0.999008   \n",
      "5237979    1.001494   1.002129  250081.44   1.002447  300167.56  1.002274   \n",
      "\n",
      "           target  \n",
      "5237975  2.310276  \n",
      "5237976 -8.220077  \n",
      "5237977  1.169443  \n",
      "5237978 -1.540184  \n",
      "5237979 -6.530285  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5237892 entries, 0 to 5237979\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Dtype  \n",
      "---  ------                   -----  \n",
      " 0   stock_id                 uint8  \n",
      " 1   date_id                  uint16 \n",
      " 2   seconds_in_bucket        uint16 \n",
      " 3   imbalance_size           float64\n",
      " 4   imbalance_buy_sell_flag  int8   \n",
      " 5   reference_price          float64\n",
      " 6   matched_size             float64\n",
      " 7   far_price                float64\n",
      " 8   near_price               float64\n",
      " 9   bid_price                float64\n",
      " 10  bid_size                 float64\n",
      " 11  ask_price                float64\n",
      " 12  ask_size                 float64\n",
      " 13  wap                      float64\n",
      "dtypes: float64(10), int8(1), uint16(2), uint8(1)\n",
      "memory usage: 469.6 MB\n",
      "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
      "0         0        0                  0      3180602.69   \n",
      "1         1        0                  0       166603.91   \n",
      "2         2        0                  0       302879.87   \n",
      "3         3        0                  0     11917682.27   \n",
      "4         4        0                  0       447549.96   \n",
      "\n",
      "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
      "0                        1         0.999812   13380276.64        NaN   \n",
      "1                       -1         0.999896    1642214.25        NaN   \n",
      "2                       -1         0.999561    1819368.03        NaN   \n",
      "3                       -1         1.000171   18389745.62        NaN   \n",
      "4                       -1         0.999532   17860614.95        NaN   \n",
      "\n",
      "   near_price  bid_price  bid_size  ask_price   ask_size  wap  \n",
      "0         NaN   0.999812  60651.50   1.000026    8493.03  1.0  \n",
      "1         NaN   0.999896   3233.04   1.000660   20605.09  1.0  \n",
      "2         NaN   0.999403  37956.00   1.000298   18995.00  1.0  \n",
      "3         NaN   0.999999   2324.90   1.000214  479032.40  1.0  \n",
      "4         NaN   0.999394  16485.54   1.000016     434.10  1.0  \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-2-a857fca50f6a>:38: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  X_test = test[~train.target.isna()]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "for (label, model) in models:\n",
    "    _ = cross_validation(\n",
    "        \n",
    "        make_pipeline(\n",
    "            ImbalanceCalculator,\n",
    "            model\n",
    "        ),\n",
    "        save_path=model_save_path,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        X_test=X_test,\n",
    "        label=label\n",
    "    )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 4714102, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (233.78 MB) transferred to GPU in 0.170063 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.043411\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 4714102, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (233.78 MB) transferred to GPU in 0.152332 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.044163\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 4714103, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (233.78 MB) transferred to GPU in 0.166304 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.043572\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 4714103, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (233.78 MB) transferred to GPU in 0.160229 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.050689\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 4714103, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (233.78 MB) transferred to GPU in 0.161864 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.046971\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 4714103, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (233.78 MB) transferred to GPU in 0.155949 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.054118\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 4714103, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (233.78 MB) transferred to GPU in 0.154351 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.051479\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 4714103, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (233.78 MB) transferred to GPU in 0.166329 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.045735\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 4714103, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (233.78 MB) transferred to GPU in 0.186210 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.049956\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 4714103, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (233.78 MB) transferred to GPU in 0.165642 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.045517\n",
      "Val Score: 6.28535 ± 0.54787 | Train Score: 6.26616 ± 0.06063 | LightGBM\n",
      "fold:0, Val Score: 5.1937007961675485, Train Score: 6.385933569237108\n",
      "fold:1, Val Score: 6.25373160273549, Train Score: 6.267043478387648\n",
      "fold:2, Val Score: 7.1899530421793765, Train Score: 6.165544325519187\n",
      "fold:3, Val Score: 6.932774630046694, Train Score: 6.195014510112975\n",
      "fold:4, Val Score: 6.7543130338622275, Train Score: 6.213064687186355\n",
      "fold:5, Val Score: 5.928349649240979, Train Score: 6.305739658798412\n",
      "fold:6, Val Score: 6.358298411319684, Train Score: 6.259008330110183\n",
      "fold:7, Val Score: 6.311505576520425, Train Score: 6.265397446309875\n",
      "fold:8, Val Score: 6.047066419391888, Train Score: 6.293370398712471\n",
      "fold:9, Val Score: 5.883774915153734, Train Score: 6.311500707833111\n",
      "Best validation score: 5.1937007961675485, associated train score: 6.385933569237108, fold:0\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 }
}